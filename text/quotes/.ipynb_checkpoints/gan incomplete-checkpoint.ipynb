{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm as tq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext.vocab import FastText\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "MIN_LENGTH = 4\n",
    "EMBEDDING_SIZE = 50\n",
    "HIDDEN_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INPUT_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a505f8644a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mquotes_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"quotes_all.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# fast_text = torchtext.vocab.FastText(language='en',cache=\"C:\\\\Users\\\\User\\\\Desktop\\\\pytorch\\\\nlp\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mglove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'6B'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mINPUT_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\User\\\\Desktop\\\\pytorch\\\\nlp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'INPUT_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "quotes_all = pd.read_csv(\"quotes_all.csv\", delimiter=\";\",header=None)\n",
    "# fast_text = torchtext.vocab.FastText(language='en',cache=\"C:\\\\Users\\\\User\\\\Desktop\\\\pytorch\\\\nlp\")\n",
    "glove = torchtext.vocab.GloVe(name='6B', dim=EMBEDDING_SIZE, cache=\"C:\\\\Users\\\\User\\\\Desktop\\\\pytorch\\\\nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(sen):\n",
    "    sen = sen.replace(\",\", \" , \").lower()\n",
    "    # specific\n",
    "    sen = re.sub(r\"won't\", \"will not\", sen)\n",
    "    sen = re.sub(r\"can\\'t\", \"can not\", sen)\n",
    "\n",
    "    # general\n",
    "    sen = re.sub(r\"n\\'t\", \" not\", sen)\n",
    "    sen = re.sub(r\"\\'re\", \" are\", sen)\n",
    "    sen = re.sub(r\"\\'s\", \" is\", sen)\n",
    "    sen = re.sub(r\"\\'d\", \" would\", sen)\n",
    "    sen = re.sub(r\"\\'ll\", \" will\", sen)\n",
    "    sen = re.sub(r\"\\'t\", \" not\", sen)\n",
    "    sen = re.sub(r\"\\'ve\", \" have\", sen)\n",
    "    sen = re.sub(r\"\\'m\", \" am\", sen)\n",
    "    \n",
    "    #stopwards\n",
    "    sen = sen.replace(\".\", \" . \")\n",
    "    sen = sen.replace(\"!\", \" ! \")\n",
    "    sen = sen.replace(\"?\", \" ? \")\n",
    "    sen = sen.replace(\"\\'\", \"\")\n",
    "    sen = sen.replace(\"-\", \" \")\n",
    "    sen = sen.replace(\"_\", \" \")\n",
    "    sen = sen.replace(\":\", \" \")\n",
    "    sen = sen.split()\n",
    "    if len(sen) > MAX_LENGTH or len(sen) < MIN_LENGTH:\n",
    "        return None\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d50012f0635>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mquotes_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquotes_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquotes_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mquotes_parsed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tq' is not defined"
     ]
    }
   ],
   "source": [
    "quotes_parsed = []\n",
    "for i in tq(range(len(quotes_all))):\n",
    "    q = parse_sentence(quotes_all[0][i])\n",
    "    if q is not None:\n",
    "        quotes_parsed.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove.get_vecs_by_tokens(quotes_parsed[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language():\n",
    "    def __init__(self):\n",
    "        self.index_to_word = {0 : \"<sos>\", 1: \"<eos>\"}\n",
    "        self.word_to_index = {\"<sos>\": 0, \"<eos>\": 1}\n",
    "        self.count = 2\n",
    "    def add_word(self, word):\n",
    "        if not self.word_to_index.__contains__(word):\n",
    "            self.word_to_index[word] = self.count\n",
    "            self.index_to_word[self.count] = word\n",
    "            self.count += 1\n",
    "    def add_sentence(self, sen):\n",
    "        for word in sen:\n",
    "            self.add_word(word)\n",
    "    def get_word(self, index):\n",
    "        return self.index_to_word[index]\n",
    "    def get_index(self, word):\n",
    "        return self.word_to_index[word]\n",
    "lang = Language()\n",
    "\n",
    "for quote in quotes_parsed:\n",
    "    lang.add_sentence(quote)\n",
    "\n",
    "VOCUB_SIZE = lang.count\n",
    "STOP_WORDS = [',', '.', '!', '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14693"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCUB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=False,\n",
    "                            bidirectional=False)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.lsm = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        output_tensor, hidden_tensor = self.lstm(input_tensor, hidden_tensor)\n",
    "        output_tensor = torch.tanh(self.linear(output_tensor.view(1,-1)))\n",
    "        return self.lsm(output_tensor), hidden_tensor\n",
    "    def init_hidden(self):\n",
    "        ##bi or single and batch, layer numbers, hidden size\n",
    "        return (torch.rand(1, 1, self.hidden_size, device=device), torch.rand(1, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(EMBEDDING_SIZE, HIDDEN_SIZE, VOCUB_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia', 'encyclopedia', 'pneumonia'] 20\n"
     ]
    }
   ],
   "source": [
    "hidden_vector = generator.init_hidden()\n",
    "words_p = []\n",
    "last_word = \"<sos>\"\n",
    "for i in range(MAX_LENGTH):\n",
    "    input_tensor = glove.__getitem__(last_word).to(device).view(1, 1, EMBEDDING_SIZE)\n",
    "    output_tensor, hidden_tensor = generator(input_tensor, hidden_vector)\n",
    "    _, predicted = torch.max(output_tensor.data, 1)\n",
    "    last_word = lang.get_word(predicted.item())\n",
    "    words_p.append(last_word)\n",
    "    if last_word in STOP_WORDS:\n",
    "        break\n",
    "print(words_p, len(words_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_p = [\"1\", \"2\", \"3\"]\n",
    "words_p[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 's', 'd']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors = glove.get_vecs_by_tokens(quotes_parsed[0]).to(device).view(-1, 1, 1, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.__getitem__(\"get\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drawstring'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.__dict__[\"itos\"][100078]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {0: \"ss\", 1: \"43\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.__contains__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
