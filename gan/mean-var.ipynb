{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Generative Adversarial Networks (GAN) example in PyTorch. Tested with PyTorch 0.4.1, Python 3.6.7 (Nov 2018)\n",
    "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_is_available = True\n",
    "try:\n",
    "  from matplotlib import pyplot as plt\n",
    "except ImportError:\n",
    "  print(\"Will skip plotting; matplotlib is not available.\")\n",
    "  matplotlib_is_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Only 4 moments]\n"
     ]
    }
   ],
   "source": [
    "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Model parameters\n",
    "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5     # Generator complexity\n",
    "    g_output_size = 1     # Size of generated output vector\n",
    "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "    d_hidden_size = 10    # Discriminator complexity\n",
    "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "    minibatch_size = d_input_size\n",
    "\n",
    "    d_learning_rate = 1e-3\n",
    "    g_learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "\n",
    "    num_epochs = 5000\n",
    "    print_interval = 100\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "    discriminator_activation_function = torch.sigmoid\n",
    "    generator_activation_function = torch.tanh\n",
    "\n",
    "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "    gi_sampler = get_generator_input_sampler()\n",
    "    G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size,\n",
    "                      f=discriminator_activation_function)\n",
    "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size))\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "\n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "\n",
    "    if matplotlib_is_available:\n",
    "        print(\"Plotting the generated distribution...\")\n",
    "        values = extract(g_fake_data)\n",
    "        print(\" Values: %s\" % (str(values)))\n",
    "        plt.hist(values, bins=50)\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Histogram of Generated Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/.local/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.5768731236457825 real_err, 0.8162738084793091 fake_err) G (0.5858615636825562 err); Real Dist ([3.998963102698326, 1.2890267900107855]),  Fake Dist ([0.0924192276597023, 0.00738687341026767]) \n",
      "Epoch 100: D (0.5890448093414307 real_err, 0.6153721809387207 fake_err) G (0.7679970264434814 err); Real Dist ([4.0519722026735545, 1.2834825789056157]),  Fake Dist ([2.036003301143646, 0.012032135172138116]) \n",
      "Epoch 200: D (0.42465078830718994 real_err, 0.4272305965423584 fake_err) G (0.9834772348403931 err); Real Dist ([3.9754500958323478, 1.3036880807733497]),  Fake Dist ([2.2036840829849242, 0.29743411971039574]) \n",
      "Epoch 300: D (0.6914812922477722 real_err, 0.675873339176178 fake_err) G (0.7106307148933411 err); Real Dist ([3.9569128542542455, 1.2765918278516917]),  Fake Dist ([9.975297571182251, 1.0607492196683244]) \n",
      "Epoch 400: D (0.2697758376598358 real_err, 0.3683095872402191 fake_err) G (1.2032607793807983 err); Real Dist ([4.005298636734485, 1.1979960603409572]),  Fake Dist ([4.931639582633972, 2.564810049034898]) \n",
      "Epoch 500: D (0.6942178606987 real_err, 0.7719638347625732 fake_err) G (0.6497299671173096 err); Real Dist ([4.0214392220973965, 1.2885527962944845]),  Fake Dist ([3.3806719698905945, 1.847252717601671]) \n",
      "Epoch 600: D (0.6893559098243713 real_err, 0.7007885575294495 fake_err) G (0.6650120615959167 err); Real Dist ([4.031770294830203, 1.2545912218596633]),  Fake Dist ([3.8112341384887696, 1.10417036325229]) \n",
      "Epoch 700: D (0.681097686290741 real_err, 0.7058270573616028 fake_err) G (0.6889208555221558 err); Real Dist ([4.0617248531579975, 1.210208542705379]),  Fake Dist ([4.007217396736145, 1.0834019578394287]) \n",
      "Epoch 800: D (0.6860408186912537 real_err, 0.7003965377807617 fake_err) G (0.6793670654296875 err); Real Dist ([3.954008603531867, 1.277041639799014]),  Fake Dist ([3.9218714323043824, 1.1428932516913832]) \n",
      "Epoch 900: D (0.6836399435997009 real_err, 0.7013078331947327 fake_err) G (0.6966800689697266 err); Real Dist ([3.9276319345235824, 1.1613655243035104]),  Fake Dist ([3.9608711774349215, 1.2217109545402955]) \n",
      "Epoch 1000: D (0.6946009993553162 real_err, 0.6989412903785706 fake_err) G (0.6873143911361694 err); Real Dist ([3.9961788846254347, 1.2236821427662035]),  Fake Dist ([3.9864257175922395, 1.2311044821901655]) \n",
      "Epoch 1100: D (0.6947442293167114 real_err, 0.6925716996192932 fake_err) G (0.6893128752708435 err); Real Dist ([3.930405654549599, 1.337853921873112]),  Fake Dist ([4.110115426778793, 1.2780765069003492]) \n",
      "Epoch 1200: D (0.7005026936531067 real_err, 0.6916640996932983 fake_err) G (0.6923094987869263 err); Real Dist ([3.994315904468298, 1.3006108658612991]),  Fake Dist ([3.9523623905181884, 1.2309206864257471]) \n",
      "Epoch 1300: D (0.6992262005805969 real_err, 0.6925655007362366 fake_err) G (0.6922256350517273 err); Real Dist ([4.068733029149473, 1.3102498564295721]),  Fake Dist ([4.017065321922302, 1.2663100891126493]) \n",
      "Epoch 1400: D (0.6938872337341309 real_err, 0.6933543682098389 fake_err) G (0.6935142874717712 err); Real Dist ([4.007041759610176, 1.2010116350863835]),  Fake Dist ([3.9226408631801606, 1.2518771226996148]) \n",
      "Epoch 1500: D (0.6952447295188904 real_err, 0.6931473016738892 fake_err) G (0.6917971968650818 err); Real Dist ([4.057095781624318, 1.3169297722595736]),  Fake Dist ([4.016021421670914, 1.1867621133827975]) \n",
      "Epoch 1600: D (0.6938917636871338 real_err, 0.6932433843612671 fake_err) G (0.6937636733055115 err); Real Dist ([4.0180571502298115, 1.2382551391935035]),  Fake Dist ([4.06113955950737, 1.2982492310133913]) \n",
      "Epoch 1700: D (0.6962283253669739 real_err, 0.6915327310562134 fake_err) G (0.6977919936180115 err); Real Dist ([4.11018240571022, 1.2927881881591168]),  Fake Dist ([4.042172157764435, 1.3636512590242615]) \n",
      "Epoch 1800: D (0.6935264468193054 real_err, 0.6928367018699646 fake_err) G (0.6938757300376892 err); Real Dist ([3.9712935922443866, 1.2314843533460726]),  Fake Dist ([3.9446922430992126, 1.3090529308006236]) \n",
      "Epoch 1900: D (0.6913382411003113 real_err, 0.6949706077575684 fake_err) G (0.6901445388793945 err); Real Dist ([3.953053653255105, 1.276475117868101]),  Fake Dist ([3.995618360757828, 1.2491621621086093]) \n",
      "Epoch 2000: D (0.6891109347343445 real_err, 0.6972134113311768 fake_err) G (0.6908391118049622 err); Real Dist ([4.011293454885482, 1.2214877932689234]),  Fake Dist ([3.981870400905609, 1.2773425906209244]) \n",
      "Epoch 2100: D (0.6928250193595886 real_err, 0.693096399307251 fake_err) G (0.6937440037727356 err); Real Dist ([4.030937267899513, 1.2271124046554245]),  Fake Dist ([4.045059245347977, 1.2850803834598192]) \n",
      "Epoch 2200: D (0.6940343379974365 real_err, 0.6927890181541443 fake_err) G (0.6928985118865967 err); Real Dist ([4.051489747911692, 1.260360310435614]),  Fake Dist ([3.884784648656845, 1.3165678778733994]) \n",
      "Epoch 2300: D (0.6932964324951172 real_err, 0.6933776140213013 fake_err) G (0.69378662109375 err); Real Dist ([3.9526764350533488, 1.1524594131517845]),  Fake Dist ([4.029943873405457, 1.2599552723437712]) \n",
      "Epoch 2400: D (0.6920108199119568 real_err, 0.6930150985717773 fake_err) G (0.6913901567459106 err); Real Dist ([4.066627781271935, 1.2644764963501254]),  Fake Dist ([4.055961115121842, 1.131193133545527]) \n",
      "Epoch 2500: D (0.6930145025253296 real_err, 0.6940463185310364 fake_err) G (0.6927071809768677 err); Real Dist ([3.925600380308926, 1.2627018115719324]),  Fake Dist ([3.9471495673656465, 1.2197576157887704]) \n",
      "Epoch 2600: D (0.6907206177711487 real_err, 0.6955429315567017 fake_err) G (0.6912346482276917 err); Real Dist ([3.9982307257810605, 1.3319256325753337]),  Fake Dist ([3.9874527785778047, 1.224629639357968]) \n",
      "Epoch 2700: D (0.6958897709846497 real_err, 0.6910514235496521 fake_err) G (0.6948670744895935 err); Real Dist ([3.9383841897025706, 1.2993046086311772]),  Fake Dist ([4.072320344209671, 1.2298957233079917]) \n",
      "Epoch 2800: D (0.6931372880935669 real_err, 0.693290114402771 fake_err) G (0.6944907307624817 err); Real Dist ([3.9034351679086687, 1.1866182983513436]),  Fake Dist ([3.9616013128757475, 1.2888164036927596]) \n",
      "Epoch 2900: D (0.694117546081543 real_err, 0.6942273378372192 fake_err) G (0.6915342807769775 err); Real Dist ([3.9919467794895174, 1.1998580318316252]),  Fake Dist ([4.013574101924896, 1.251487613839665]) \n",
      "Epoch 3000: D (0.6925148367881775 real_err, 0.6944974064826965 fake_err) G (0.6939089894294739 err); Real Dist ([3.911329732298851, 1.1700065654102312]),  Fake Dist ([4.003117864608765, 1.2198075587179944]) \n",
      "Epoch 3100: D (0.6922937631607056 real_err, 0.6922882795333862 fake_err) G (0.6919430494308472 err); Real Dist ([4.138760205626488, 1.2979021609647237]),  Fake Dist ([3.868668614149094, 1.2393713632359153]) \n",
      "Epoch 3200: D (0.6918120980262756 real_err, 0.6941818594932556 fake_err) G (0.6929519176483154 err); Real Dist ([4.023906213283539, 1.2165908375943935]),  Fake Dist ([4.091359052419662, 1.2527001887128952]) \n",
      "Epoch 3300: D (0.6944679021835327 real_err, 0.6913018822669983 fake_err) G (0.6944875121116638 err); Real Dist ([3.864681752741337, 1.15733963536687]),  Fake Dist ([4.0099808235168455, 1.3069321762974997]) \n",
      "Epoch 3400: D (0.6922825574874878 real_err, 0.6921380162239075 fake_err) G (0.6924254894256592 err); Real Dist ([3.946053055644035, 1.230527181981505]),  Fake Dist ([3.9960645096302034, 1.1609168111481147]) \n",
      "Epoch 3500: D (0.6915767788887024 real_err, 0.6945587992668152 fake_err) G (0.6913950443267822 err); Real Dist ([3.95911438447237, 1.2706026844016074]),  Fake Dist ([4.00390850186348, 1.287754200153497]) \n",
      "Epoch 3600: D (0.692298412322998 real_err, 0.6957177519798279 fake_err) G (0.6925060153007507 err); Real Dist ([3.9521096405386924, 1.1615540981999892]),  Fake Dist ([4.010527317762375, 1.172707700246352]) \n",
      "Epoch 3700: D (0.6981837749481201 real_err, 0.6986427903175354 fake_err) G (0.6873040795326233 err); Real Dist ([4.016827707827091, 1.2249625094190333]),  Fake Dist ([3.9066930205821992, 1.2059935192382032]) \n",
      "Epoch 3800: D (0.6933016777038574 real_err, 0.693265438079834 fake_err) G (0.6928241848945618 err); Real Dist ([3.9013163988515736, 1.3054681035625113]),  Fake Dist ([4.020622292280197, 1.3590296070254586]) \n",
      "Epoch 3900: D (0.6954911947250366 real_err, 0.6924591064453125 fake_err) G (0.6924023032188416 err); Real Dist ([3.9844671229720117, 1.1943434214607767]),  Fake Dist ([4.080291921377182, 1.231074856722369]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000: D (0.6921380162239075 real_err, 0.6940876841545105 fake_err) G (0.6914846301078796 err); Real Dist ([3.9930063731372356, 1.2280395295525008]),  Fake Dist ([3.997506716966629, 1.2170871408014667]) \n",
      "Epoch 4100: D (0.6930111646652222 real_err, 0.693920910358429 fake_err) G (0.6929721832275391 err); Real Dist ([3.954937932372093, 1.2413510672012606]),  Fake Dist ([3.985257079124451, 1.2521719241967735]) \n",
      "Epoch 4200: D (0.6944907307624817 real_err, 0.6949186325073242 fake_err) G (0.6920937895774841 err); Real Dist ([4.012155459877103, 1.1857437398645319]),  Fake Dist ([3.9778176267147063, 1.200579873639327]) \n",
      "Epoch 4300: D (0.6924999356269836 real_err, 0.694759726524353 fake_err) G (0.6913988590240479 err); Real Dist ([4.081928184688091, 1.242382953179434]),  Fake Dist ([3.965589499473572, 1.2278350355131087]) \n",
      "Epoch 4400: D (0.6939080357551575 real_err, 0.6931775808334351 fake_err) G (0.6927916407585144 err); Real Dist ([4.053898994207382, 1.226251248530528]),  Fake Dist ([4.055085018396378, 1.169791939639245]) \n",
      "Epoch 4500: D (0.6924003958702087 real_err, 0.69416743516922 fake_err) G (0.6918049454689026 err); Real Dist ([4.048051754210144, 1.2480871592677167]),  Fake Dist ([3.959045846939087, 1.2693574084738812]) \n",
      "Epoch 4600: D (0.6923105716705322 real_err, 0.6940383315086365 fake_err) G (0.692686915397644 err); Real Dist ([4.011629379451275, 1.2462811080679126]),  Fake Dist ([4.051776837348938, 1.2447574593978812]) \n",
      "Epoch 4700: D (0.6939893960952759 real_err, 0.6927457451820374 fake_err) G (0.6938271522521973 err); Real Dist ([3.9357289199233056, 1.2546793532314768]),  Fake Dist ([4.009269228219986, 1.2572747697016868]) \n",
      "Epoch 4800: D (0.6910876035690308 real_err, 0.6949467062950134 fake_err) G (0.693804919719696 err); Real Dist ([3.9709926743507387, 1.210342046288097]),  Fake Dist ([3.9912657163143157, 1.279534179854469]) \n",
      "Epoch 4900: D (0.6943165063858032 real_err, 0.6926029920578003 fake_err) G (0.6933717131614685 err); Real Dist ([4.108102389454841, 1.1930080663492781]),  Fake Dist ([4.046253533601761, 1.1953455988239767]) \n",
      "Plotting the generated distribution...\n",
      " Values: [3.6995902061462402, 5.841672897338867, 3.327853202819824, 3.85418701171875, 5.07649040222168, 6.435767650604248, 3.7346129417419434, 3.65048885345459, 1.561952829360962, 3.5524444580078125, 2.1637444496154785, 3.885601043701172, 6.356627941131592, 3.0103366374969482, 3.744016647338867, 3.7078685760498047, 4.966719627380371, 3.244502544403076, 5.051693916320801, 3.296311855316162, 5.028412818908691, 3.4016876220703125, 4.3811936378479, 4.8849945068359375, 3.395606279373169, 4.197253704071045, 6.45343017578125, 4.942320823669434, 3.889212131500244, 3.7139132022857666, 3.822645664215088, 3.606184482574463, 3.754058599472046, 2.343259572982788, 6.161479473114014, 2.552473545074463, 4.257865905761719, 3.9347424507141113, 3.8156824111938477, 6.1670660972595215, 4.184110641479492, 2.5754499435424805, 2.6483078002929688, 3.808140754699707, 2.4283993244171143, 5.6135101318359375, 4.514677047729492, 3.2013185024261475, 4.8346452713012695, 3.594853639602661, 3.8154425621032715, 4.924444675445557, 4.981571674346924, 3.3841116428375244, 2.3363165855407715, 6.521538734436035, 3.0336456298828125, 6.580017566680908, 3.290053367614746, 3.061225652694702, 3.074955463409424, 4.10446834564209, 4.368048191070557, 3.7379419803619385, 3.3081703186035156, 3.9799797534942627, 3.8806724548339844, 3.3350729942321777, 4.786360740661621, 2.4116733074188232, 5.7091827392578125, 2.6926774978637695, 4.217368125915527, 5.2256317138671875, 4.945821762084961, 3.683943271636963, 3.2024707794189453, 3.5588207244873047, 5.853531360626221, 1.6427139043807983, 4.210622787475586, 3.7917985916137695, 2.7188973426818848, 3.7470550537109375, 3.7776994705200195, 6.289484977722168, 4.700468063354492, 1.4686665534973145, 4.531262397766113, 3.8342628479003906, 3.8019871711730957, 4.813107013702393, 1.9552310705184937, 4.447042465209961, 2.212266445159912, 3.649383544921875, 5.246783256530762, 2.647611618041992, 4.065554618835449, 2.977205753326416, 3.929741859436035, 1.9541562795639038, 4.216316223144531, 6.64766263961792, 2.6733036041259766, 2.8264951705932617, 5.164873123168945, 3.385592460632324, 4.2058916091918945, 4.773637771606445, 3.8594653606414795, 3.6319167613983154, 3.1608152389526367, 3.8364675045013428, 3.588359832763672, 5.695317268371582, 4.462191104888916, 4.411054611206055, 1.5014997720718384, 4.518220901489258, 3.7455475330352783, 4.645184516906738, 4.846047878265381, 3.168527126312256, 2.4556169509887695, 6.452341556549072, 6.139791011810303, 3.7494311332702637, 4.07169771194458, 4.086906909942627, 3.14106822013855, 4.049391746520996, 3.703618288040161, 3.575690269470215, 3.788573741912842, 3.6238672733306885, 4.337016582489014, 3.505093574523926, 3.9516520500183105, 1.6286017894744873, 1.5756434202194214, 2.4751975536346436, 3.9054713249206543, 2.924866199493408, 5.1749114990234375, 6.487346172332764, 3.7797930240631104, 4.77177095413208, 5.569281578063965, 4.866204261779785, 3.6445789337158203, 5.546038627624512, 2.964905261993408, 4.037578582763672, 3.6113858222961426, 5.436519622802734, 6.455661773681641, 4.422257423400879, 2.375779867172241, 4.664908409118652, 3.390782117843628, 6.669110298156738, 1.6437264680862427, 4.045191764831543, 4.472140789031982, 4.2508978843688965, 6.066903591156006, 5.908944129943848, 3.992177963256836, 3.9477429389953613, 3.6811811923980713, 4.240672588348389, 2.3350377082824707, 3.9765093326568604, 1.6266173124313354, 3.847888231277466, 4.003030776977539, 5.705279350280762, 3.1008548736572266, 3.0644800662994385, 3.78322172164917, 3.451441526412964, 5.143893241882324, 5.6240644454956055, 5.760892391204834, 5.82698392868042, 3.928980827331543, 3.4930858612060547, 5.273872375488281, 3.7611477375030518, 3.4951438903808594, 3.9688124656677246, 3.748826503753662, 3.400050640106201, 3.8658976554870605, 6.086569309234619, 6.530248165130615, 4.42825984954834, 6.446532726287842, 6.5013837814331055, 3.782745361328125, 5.722817420959473, 3.1440184116363525, 6.314965724945068, 3.763474464416504, 6.034368991851807, 3.67671275138855, 6.595545768737793, 4.859373092651367, 5.217380523681641, 3.9792368412017822, 4.836394309997559, 4.361870765686035, 1.7586220502853394, 4.037019729614258, 5.313594818115234, 4.467615604400635, 0.9799684286117554, 4.7485504150390625, 1.833777904510498, 4.0062432289123535, 1.6670855283737183, 3.8899683952331543, 1.9614063501358032, 6.613918781280518, 3.297792673110962, 2.341468095779419, 4.168871879577637, 6.204131126403809, 3.9971718788146973, 1.8749974966049194, 6.459418773651123, 3.779923439025879, 4.093571662902832, 5.546504974365234, 3.8872227668762207, 3.7979116439819336, 4.857539176940918, 4.067821979522705, 3.638852834701538, 3.874558448791504, 3.836153507232666, 3.00628662109375, 3.862241268157959, 3.5291690826416016, 5.615967273712158, 3.8992228507995605, 6.187863349914551, 5.614862442016602, 3.98398494720459, 3.1397464275360107, 2.020115375518799, 4.29356050491333, 5.775259971618652, 6.471776485443115, 2.2086048126220703, 3.6039605140686035, 2.899405002593994, 4.757565498352051, 5.605566024780273, 4.316326141357422, 3.1439690589904785, 3.2225444316864014, 3.394659996032715, 3.9312455654144287, 4.516859531402588, 3.639460325241089, 4.683189392089844, 3.829662322998047, 3.3271164894104004, 2.920586109161377, 5.698534965515137, 3.963841438293457, 4.723033905029297, 5.8134026527404785, 3.631800889968872, 3.604222536087036, 6.507528781890869, 1.822885274887085, 5.933992862701416, 5.7471466064453125, 2.4362826347351074, 2.4177398681640625, 3.6545958518981934, 4.173192977905273, 4.34593391418457, 3.798537492752075, 5.060652732849121, 4.510858535766602, 3.22402286529541, 3.756674289703369, 5.274046897888184, 1.1798598766326904, 2.9261410236358643, 4.832917213439941, 3.8867692947387695, 3.917203903198242, 4.5566205978393555, 5.848784923553467, 4.19303035736084, 2.0413336753845215, 5.763141632080078, 3.9988627433776855, 3.874988079071045, 4.253464698791504, 4.284880638122559, 5.892484188079834, 1.2712711095809937, 5.080246925354004, 5.2319440841674805, 4.116155624389648, 3.3670685291290283, 4.4828290939331055, 3.670994758605957, 3.5857505798339844, 4.228017807006836, 3.471970558166504, 3.6039950847625732, 3.974351644515991, 4.456457138061523, 4.333930015563965, 3.710690975189209, 6.676777362823486, 3.927844524383545, 5.425291061401367, 5.762022972106934, 2.2096781730651855, 6.493513584136963, 3.925333023071289, 4.554574966430664, 5.278342247009277, 2.6862730979919434, 5.769104480743408, 4.120311260223389, 6.185617446899414, 3.9611189365386963, 4.925604820251465, 2.0052390098571777, 5.87060546875, 1.1567732095718384, 4.512265205383301, 4.696199417114258, 5.983407497406006, 4.000811576843262, 3.5098114013671875, 6.216528415679932, 4.115423202514648, 4.113390922546387, 6.525055408477783, 4.063302993774414, 6.004035949707031, 4.388785362243652, 3.7290396690368652, 3.620208263397217, 4.8035407066345215, 3.7804219722747803, 5.022190093994141, 5.201873779296875, 3.0395402908325195, 1.59952974319458, 1.1957790851593018, 3.940460443496704, 3.7054247856140137, 3.6894497871398926, 3.773144483566284, 4.971546173095703, 3.5077333450317383, 3.978177309036255, 2.836561441421509, 4.033509731292725, 5.997369766235352, 4.094786643981934, 3.7949516773223877, 3.454810619354248, 3.897894859313965, 3.750196933746338, 3.8720364570617676, 4.795270919799805, 3.961548328399658, 3.9922423362731934, 1.3427162170410156, 6.007556438446045, 4.290058135986328, 3.7047462463378906, 5.424725532531738, 6.360915660858154, 4.115769386291504, 3.0854084491729736, 4.472530364990234, 3.9368975162506104, 2.2915399074554443, 2.941063642501831, 3.5103700160980225, 4.452528953552246, 4.58350944519043, 2.69702410697937, 2.9711997509002686, 3.51416015625, 4.185305118560791, 3.563941478729248, 2.313343048095703, 3.796177864074707, 3.8318047523498535, 3.366590738296509, 6.116869926452637, 3.467649221420288, 4.652191638946533, 3.8202834129333496, 3.7323591709136963, 4.585912704467773, 3.780942916870117, 3.610276460647583, 5.045480728149414, 4.517258167266846, 4.04982328414917, 3.8998501300811768, 2.9480702877044678, 3.8765461444854736, 4.2130513191223145, 3.9844510555267334, 3.007878541946411, 4.359312057495117, 3.444516181945801, 5.456793785095215, 4.3670454025268555, 4.669894695281982, 4.091410160064697, 4.267399787902832, 4.2058610916137695, 3.7370190620422363, 4.206237316131592, 3.1757850646972656, 1.5197714567184448, 3.9277150630950928, 5.553036689758301, 3.2307560443878174, 5.12728214263916, 3.9092931747436523, 2.644420623779297, 5.34705924987793, 5.15653133392334, 1.3013525009155273, 5.973147869110107, 3.1647655963897705, 2.2143123149871826, 5.152701377868652, 4.012278079986572, 1.5248961448669434, 3.505164623260498, 3.9719064235687256, 3.770503520965576, 4.3644609451293945, 3.803964614868164, 4.241710186004639, 4.090931415557861, 4.157922744750977, 3.8908023834228516, 4.422223091125488, 4.236695289611816, 3.83430552482605, 1.9822843074798584, 6.142265796661377, 3.7332887649536133, 3.9164066314697266, 4.689937114715576, 3.349107265472412, 3.5977272987365723, 6.059330940246582, 6.304284572601318, 2.178499937057495, 5.32572078704834, 2.990372657775879, 1.5477583408355713, 3.588493824005127, 1.90336275100708, 4.191643714904785, 3.7054831981658936, 6.101456642150879, 1.1661630868911743, 5.227060317993164, 3.017061471939087, 5.594265937805176, 2.7821829319000244, 4.083248615264893, 4.035520553588867, 4.823718070983887, 3.2270901203155518, 4.203372001647949, 3.028031349182129, 3.941927909851074, 4.3243184089660645, 4.569843292236328, 3.8571484088897705, 3.853283166885376, 2.1852378845214844, 2.1085798740386963, 6.686854839324951, 3.4301555156707764, 5.4867167472839355, 5.765778064727783]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHgxJREFUeJzt3X+cXXV95/HXm0AkZiBRSachQQaLtatkRTNSFWtnQFoqWmCXbaFIoaLRbeUha6QiqxXWX7gVcKtd1wgUFMrIIoiCv1JgoHRFnEB0COBDiokQIBEIgQFUQj77x/kOubnMnftj7rnnzj3v5+NxH3PPueec7+d77p37ued7vud7FBGYmVl57VJ0AGZmViwnAjOzknMiMDMrOScCM7OScyIwMys5JwIzs5JzIphlJK2TNFR0HEWSdLSk+yRNSHpN0fEUTdKZki6Z4TYmJL2sTfGcIen89HxAUkjatU3bfmmKdU47tmcZJ4IuImm9pLdUzTtJ0s2T0xHxqogYrbOdtv7zdaHPAu+LiL6IuL36RWXeJ+knkp6S9JCkUUnHFhBrXVO9723c9pCk7enLc0LS/ZIul/S6yuXSvry3gW3dX6/MiPhURLxrprGnMnfaNxHxixTrs+3YvmWcCKxpXZBg9gXWTfP6PwCnAiuBlwBLgI8Ah+cf2s66YF8BPBARfcAewOuBu4F/lXRouwvqkvpasyLCjy55AOuBt1TNOwm4eaplgIOAMeBxYBNwbpr/CyCAifR4A1nS/wiwAdgMfAVYULHdv0yvPQJ8tKqcM4ErgEtSWe9KZf8AeAx4EPgCMLdiewH8NfAz4Ang48DvAP8vbePyyuWr6jxlrMALUn0CeBL49ynW/V3gWWCwzr5eAFyQYt8IfAKYU7nPyY48tgA/B/6kiXX/DTgv7ctPpHpfn6YfBi4FFqblvwpsB55OdfvbNP/1aV89BvwYGKoofz/gxrRfV6d9f0mNeg4B908x/wvAWNX7tX96/lbgzrT9jcAHgfkpxu3s+FztXeOzceZkPMBA2vYK4IG0zz5YUe5FwCemineqfVOxvV3TMnsD3wQeBe4B3l2xrTPJPmdfSXVZV+9zUdZH4QH4UfFmNJ8IfgCckJ73Aa9Pz3f6Z0nz3pn+UV6Wlr0S+Gp67ZXpH+1NwFyyL8Bn2DkRPAMcRfYlPQ9YTvZltWsq7y7g1IryArga2BN4FfBr4LpU/oL0RXNijf1QM9aKbe9fY933Ausb2NdXAV8i+4L7LeBW4D0V+/wZ4N3AHOC/pi8xNbjuNuCUtG/mAfsDh5ElskXATcDnar3vZEcwj5B9Ie+S1n0EWFTxvp+btvdmsi+5ZhPBIWRfsvOr9ynZl/UfpOcvAl5ba1s1Phtn8vxEcFnaX8uAX7Ljs3URNRJBjX0zub3JRHAT8L+B3YED07YPqYjtV2k/zgE+DdxS9P95Nz7cNNR9viHpsckH2Ye8lmeA/SXtFRETEXHLNMseT3bEcG9ETAAfBo5Nh/LHAN+KiJsj4jfA35H9s1X6QUR8IyK2R8TTEbEmIm6JiG0RsZ7si/EPq9b5nxHxeESsA+4Avp/K3wp8B6h1one6WOvZC3iockZqF39M0q8k7Supn+zL4dSIeDIiNpP9gq88h7AhIr4cWVv0xcBioL/BdR+IiM+nffN0RNwTEasj4tcR8UuyL/HqfVXpHcC3I+LbaX+vJjvye6uklwKvAz6atncT8K0G9ku1BwABC6d47RnglZL2jIgtEXFbnW3t9NmoscxZaX+NA/8EHNdCzDuRtA9wMPChiPhVRKwFzic7up10c9qPz5IdYbx6puX2IieC7nNURCycfJA1r9RyMllTyN2SfiTpbdMsuzdZU8ukDWS/WPvTa/dNvhART5H9Aq10X+WEpN+VdE06Efs48CmyL+FKmyqePz3FdF8LsdbzCNmX9nMiYmmK7QVkX377ArsBD1Yk3C+R/bqf9FDF+k+lp30Nrlu9r/oljUjamPbVJTx/X1XaF/gvVT8I3pTqtTewJSKerFh+w1QbqWMJWbJ/bIrX/jNZstsg6UZJb6izrfvqvF69zAayeszU3sCjEfFE1baXVExX/ih4Ctjd5zGez4lgFouIn0XEcWRfQp8BrpA0n+f/mofsF+C+FdMvJWvC2ETWFLB08gVJ88hOsu5UXNX0F8lOOr48IvYEziD7km2H6WKt53pgqaTBaZa5j6ypaq+KpLtnRLyqge03sm71vvpUmrcs7at3sPO+ql7+PrKmsIUVj/kRcTbZe/Wi9D5PemkDcVc7GritKqFkwUT8KCKOJPtcfYOsnX2qOGvFP5V9Kp6/lOw9huxczwsrXvvtJrb9APBiSXtUbXtjA/FYBSeCWUzSOyQtiojt7Phlt52snXQ7WRv7pMuA/yZpP0l9ZF9OX4uIbWQn+94u6Y2S5pK1rdb7Ut+D7OTghKTfI2tHb5fpYp1WRPyU7Bf6iKTDJM1Lfc7fWLHMg8D3gXMk7SlpF0m/I2m65pqZrLsH2TmYrZKWAKdVvb6Jnd+rS8jejz+WNEfS7qnr5tKI2EDWTHSWpLmS3gS8vV7c8Fy32iWSPkZ2UveMKZaZK+l4SQsi4hmy93h7RZwvkbSgkfKqfFTSCyW9Cvgr4Gtp/lqyJq8XS/ptst5elar3zXMi4j6yE+qfTvvoP5IdJc/omooyciKY3Q4H1kmaAP4XcGxqk34K+CTwb6lp4fXAhWRtpDeR9YL5FdkJTVIb/inACNkvzgmy3jq/nqbsDwJ/QXai8svs+Mduh5qxNuhvyLqQnkvWm+R+sl5Lf07WowqyduS5ZCett5Alw8XP29LUml33LOC1wFbgWrKT35U+DXwkvVcfTF9wR5J9Uf+S7AjhNHb8v/4F8Pupbh8j6xUznb3TZ2QC+BHZCduhiPh+jeVPANanZqz3kp2zISLuJkvS96ZYm2neuZGsA8B1wGcryv4qWa+o9WQJtvpztNO+mWK7x5GdQH6A7CT+xyLiX5qIy9jRC8LsOelX+GNkzT4/LzoeM8uXjwgMAElvT4fu88m6j46T/Uozsx7nRGCTjiQ7vH4AeDlZM5MPF81KwE1DZmYl5yMCM7OSmxUXVuy1114xMDDQ8vpPPvkk8+fPr7/gLNOL9XKdZo9erFev1WnNmjUPR8SiesvNikQwMDDA2NhYy+uPjo4yNDTUvoC6RC/Wy3WaPXqxXr1WJ0kNXXXupiEzs5JzIjAzKzknAjOzknMiMDMrOScCM7OScyIwMyu53BNBGkb3dknXpOn9JP1Q0j2SvpaGPTYzs4J04ojg/WT3s530GeC8iNifbAjfkzsQg5mZ1ZBrIpC0FDiC7D6iSBLZTbOvSItcTHbTazMzK0iug85JuoLsxhJ7kN3I5CTglnQ0MHnz6e9ExAFTrLsCWAHQ39+/fGRkpOU4JiYm6OurdXvc2asX69WtdRrfuHXK+cuW1L9ZV7fWaaZ6sV69Vqfh4eE1ETHdbVuBHIeYSDdS3xwRayQNNbt+RKwCVgEMDg7GTC777rXLxif1Yr26tU4nnX7tlPPXHz9Ud91urdNM9WK9erFOjchzrKGDgT+V9FZgd2BPstspLpS0a7r/7FJ8o2kzs0Lldo4gIj4cEUsjYgA4Frg+Io4HbgCOSYudCFydVwxmZlZfEdcRfAj4gKR7gJcAFxQQg5mZJR0ZhjoiRoHR9Pxe4KBOlGuWt4Fa5w7OPqLDkZi1zlcWm5mVnBOBmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWcnllggk7S7pVkk/lrRO0llp/kWSfi5pbXocmFcMZmZWX553KPs1cEhETEjaDbhZ0nfSa6dFxBU5lm1mZg3KLRFERAATaXK39Ii8yjMzs9bkeo5A0hxJa4HNwOqI+GF66ZOSfiLpPEkvyDMGMzObnrIf7jkXIi0ErgJOAR4BHgLmAquAf4+I/zHFOiuAFQD9/f3LR0ZGWi5/YmKCvr6+ltfvVr1Yr26t0/jGrU0tv2zJgueed2udZqoX69VrdRoeHl4TEYP1lutIIgCQ9HfAUxHx2Yp5Q8AHI+Jt0607ODgYY2NjLZc9OjrK0NBQy+t3q16sV7fWaeD0a5tafv3ZRzz3vFvrNFO9WK9eq5OkhhJBnr2GFqUjASTNAw4D7pa0OM0TcBRwR14xmJlZfXn2GloMXCxpDlnCuTwirpF0vaRFgIC1wHtzjMHMzOrIs9fQT4DXTDH/kLzKNDOz5vnKYjOzknMiMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzknMiMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzknMiMDMrOScCM7OScyIwMys5JwIzs5LL857Fu0u6VdKPJa2TdFaav5+kH0q6R9LXJM3NKwYzM6svzyOCXwOHRMSrgQOBwyW9HvgMcF5E7A9sAU7OMQYzM6sjt0QQmYk0uVt6BHAIcEWafzFwVF4xmJlZfYqI/DYuzQHWAPsD/wj8PXBLOhpA0j7AdyLigCnWXQGsAOjv718+MjLSchwTExP09fW1vH636sV6dWudxjdubWr5ZUsWPPe8W+s0U71Yr16r0/Dw8JqIGKy33K55BhERzwIHSloIXAX8XhPrrgJWAQwODsbQ0FDLcYyOjjKT9btVL9arW+t00unXNrX8+uOHnnverXWaqV6sVy/WqREd6TUUEY8BNwBvABZKmkxAS4GNnYjBzMymlmevoUXpSABJ84DDgLvIEsIxabETgavzisHMzOrLs2loMXBxOk+wC3B5RFwj6U5gRNIngNuBC3KMwczM6sgtEUTET4DXTDH/XuCgvMo1M7Pm5Hqy2KysBipOLq9ctm2nk83rzz6iiJDMavIQE2ZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWch6G2qzCQJP3JjbrBT4iMDMruTzvWbyPpBsk3SlpnaT3p/lnStooaW16vDWvGMzMrL48m4a2ASsj4jZJewBrJK1Or50XEZ/NsWwzM2tQnvcsfhB4MD1/QtJdwJK8yjMzs9YoIvIvRBoAbgIOAD4AnAQ8DoyRHTVsmWKdFcAKgP7+/uUjIyMtlz8xMUFfX1/L63erXqxX0XUa37i17dvsnwebnt4xvWzJgraXUYSi36s89FqdhoeH10TEYL3lck8EkvqAG4FPRsSVkvqBh4EAPg4sjoh3TreNwcHBGBsbazmG0dFRhoaGWl6/W/VivYquUx69hlYu28Y54zsOvnvl5vVFv1d56LU6SWooEeTaa0jSbsDXgUsj4kqAiNgUEc9GxHbgy8BBecZgZmbTy7PXkIALgLsi4tyK+YsrFjsauCOvGMzMrL48ew0dDJwAjEtam+adARwn6UCypqH1wHtyjMHMzOrIs9fQzYCmeOnbeZVpZmbN85XFZmYl50RgZlZyTgRmZiXXUCKQdHAj88zMbPZp9Ijg8w3OMzOzWWbaXkOS3gC8EVgk6QMVL+0JzMkzMDMz64x63UfnAn1puT0q5j8OHJNXUGZm1jnTJoKIuBG4UdJFEbGhQzGZmVkHNXpB2QskrQIGKteJiEPyCMrMzDqn0UTwf4H/A5wPPJtfOGZm1mmNJoJtEfHFXCMxK7laQ2D3yrDV1r0a7T76LUl/LWmxpBdPPnKNzMzMOqLRI4IT09/TKuYF8LL2hmNmZp3WUCKIiP3yDsTMzIrRUCKQ9JdTzY+Ir7Q3HDMz67RGm4ZeV/F8d+BQ4DbAicBmpTzuTWw2WzXaNHRK5bSkhcBILhGZmVlHtToM9ZPAtOcNJO0j6QZJd0paJ+n9af6LJa2W9LP090UtxmBmZm3Q6DmCb5H1EoJssLn/AFxeZ7VtwMqIuE3SHsAaSauBk4DrIuJsSacDpwMfaiV4MzObuUbPEXy24vk2YENE3D/dChHxIPBgev6EpLuAJcCRwFBa7GJgFCcCM7PCKCLqLwVI6mfHSeNbI2Jzw4VIA8BNwAHALyJiYZovYMvkdNU6K4AVAP39/ctHRlo/JTExMUFfX1/L63erXqxXp+o0vnFr7mVM6p8Hm57eMb1syYIpl6sVU63li+bPX/cbHh5eExGD9ZZrKBFI+jPg78l+vQv4A+C0iLiigXX7gBuBT0bElZIeq/zil7QlIqY9TzA4OBhjY2N146xldHSUoaGhltfvVr1Yr07VqZO9hlYu28Y54zsOvmsNGTHbhpjw56/7SWooETTaNPTfgddNHgVIWgT8CzBtIpC0G/B14NKIuDLN3iRpcUQ8KGkx0PCRhZmZtV+jvYZ2qWoKeqTeuqnZ5wLgrog4t+Klb7JjyIoTgasbjMHMzHLQ6BHBdyV9D7gsTf858O066xwMnACMS1qb5p0BnA1cLulkYAPwZ82FbGZm7VTvnsX7A/0RcZqk/wS8Kb30A+DS6daNiJvJzidM5dBmAzXrFb6q2bpNvSOCzwEfBkht/FcCSFqWXnt7rtGZmVnu6p0j6I+I8eqZad5ALhGZmVlH1UsEz+vfX2FeOwMxM7Ni1EsEY5LeXT1T0ruANfmEZGZmnVTvHMGpwFWSjmfHF/8gMBc4Os/AzMysM6ZNBBGxCXijpGGy4SEAro2I63OPzMymNduuRLbu1ej9CG4Absg5FjMzK0Cr9yMwM7Me4URgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnK5JQJJF0raLOmOinlnStooaW16vDWv8s3MrDF5HhFcBBw+xfzzIuLA9Kh332MzM8tZbokgIm4CHs1r+2Zm1h6KiPw2Lg0A10TEAWn6TOAk4HFgDFgZEVtqrLsCWAHQ39+/fGRkpOU4JiYm6Ovra3n9btUL9RrfuHWn6f55sOlpWLZkQUfLzdNknVpVa1/UqkOz+67V7fTC569ar9VpeHh4TUQM1luu04mgH3gYCODjwOKIeGe97QwODsbY2FjLcYyOjjI0NNTy+t2qF+pVPab+ymXbOGd819zH1K81ln8eJuvUqlr7ol33I2h1O73w+avWa3WS1FAi6GivoYjYFBHPRsR24MvAQZ0s38zMnq+jiUDS4orJo4E7ai1rZmad0frxah2SLgOGgL0k3Q98DBiSdCBZ09B64D15lW9mZo3JLRFExHFTzL4gr/LMelUnz2dYOfnKYjOzknMiMDMrOScCM7OScyIwMyu53E4Wm3UDn2g1q89HBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyHmLCZpV23afXeos/FzPjIwIzs5LLLRFIulDSZkl3VMx7saTVkn6W/r4or/LNzKwxeR4RXAQcXjXvdOC6iHg5cF2aNjOzAuWWCCLiJuDRqtlHAhen5xcDR+VVvpmZNUYRkd/GpQHgmog4IE0/FhEL03MBWyanp1h3BbACoL+/f/nIyEjLcUxMTNDX19fy+t2qF+o1vnHrTtP982DT0wUFk5NO12nZkgVNLV/9HjS6nSI+f7ViraXZfdEL/1OVhoeH10TEYL3lCus1FBEhqWYWiohVwCqAwcHBGBoaarms0dFRZrJ+t+qFep1U1dtj5bJtnDPeW53ZOl2n9ccPNbV89XvQ6HaK+PzVirWWZvdFL/xPtaLTvYY2SVoMkP5u7nD5ZmZWpdOJ4JvAien5icDVHS7fzMyq5Nl99DLgB8ArJN0v6WTgbOAwST8D3pKmzcysQLk1XEbEcTVeOjSvMs2stlpX3xZV7my66rdddejWfeEri83MSs6JwMys5JwIzMxKzonAzKzkeuvKHTNrm3onl1cu27bTBV5Fn/C01vmIwMys5JwIzMxKzonAzKzknAjMzErOicDMrOTcayhHRV1O3q2XsVtvK2oIi+k0+78wvnFr00NdN1NuK8t34v/WRwRmZiXnRGBmVnJOBGZmJedEYGZWcj5ZPAvUOpF00eHz27KdWnxyeXbqxpO23abWPlq5rMOBdAkfEZiZlVwhRwSS1gNPAM8C2yJisIg4zMys2Kah4Yh4uMDyzcwMNw2ZmZWeIqLzhUo/B7YAAXwpIlZNscwKYAVAf3//8pGRkZbLm5iYoK+vr+X16xnfuLWp5ZctWdCW7e+3YM6U9Wo2nlpqxVlr+83Wa6pt9c+DTU83vZmu1ot1gpnXqx2fl3Zrtk7N/o+0opX9NGl4eHhNI03vRSWCJRGxUdJvAauBUyLiplrLDw4OxtjYWMvljY6OMjQ01PL69eTdG2e6XkNT1atdvUZqxdnOISyqt7Vy2TbOGe+tzmy9WCeYeb3a8Xlpt2br1Oz/SCtm0ntPUkOJoJCmoYjYmP5uBq4CDioiDjMzKyARSJovaY/J58AfAXd0Og4zM8sUcbzaD1wlabL8f46I7xYQh5mZUUAiiIh7gVd3utxqHqq5/YoeStdmF39euoe7j5qZlZwTgZlZyTkRmJmVnBOBmVnJ9d5VLrNYsxehtOv+qrW086IYD41szZgtn5fZEmc9PiIwMys5JwIzs5JzIjAzKzknAjOzkvPJ4iqduOK4V04wmVlv8BGBmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyfV8r6GB069l5bJtMx6KwT19zKxX+YjAzKzkCkkEkg6X9FNJ90g6vYgYzMwsU8TN6+cA/wj8CfBK4DhJr+x0HGZmliniiOAg4J6IuDcifgOMAEcWEIeZmQGKiM4WKB0DHB4R70rTJwC/HxHvq1puBbAiTb4C+OkMit0LeHgG63erXqyX6zR79GK9eq1O+0bEonoLdW2voYhYBaxqx7YkjUXEYDu21U16sV6u0+zRi/XqxTo1ooimoY3APhXTS9M8MzMrQBGJ4EfAyyXtJ2kucCzwzQLiMDMzCmgaiohtkt4HfA+YA1wYEetyLrYtTUxdqBfr5TrNHr1Yr16sU10dP1lsZmbdxVcWm5mVnBOBmVnJ9XQikHShpM2S7ig6lnaRtI+kGyTdKWmdpPcXHVM7SNpd0q2SfpzqdVbRMbWLpDmSbpd0TdGxtIOk9ZLGJa2VNFZ0PO0gaaGkKyTdLekuSW8oOqZO6ulzBJLeDEwAX4mIA4qOpx0kLQYWR8RtkvYA1gBHRcSdBYc2I5IEzI+ICUm7ATcD74+IWwoObcYkfQAYBPaMiLcVHc9MSVoPDEZEz1x4Jeli4F8j4vzUm/GFEfFY0XF1Sk8fEUTETcCjRcfRThHxYETclp4/AdwFLCk2qpmLzESa3C09Zv2vFElLgSOA84uOxaYmaQHwZuACgIj4TZmSAPR4Iuh1kgaA1wA/LDaS9khNKGuBzcDqiOiFen0O+Ftge9GBtFEA35e0Jg0FM9vtB/wS+KfUhHe+pPlFB9VJTgSzlKQ+4OvAqRHxeNHxtENEPBsRB5JdbX6QpFndnCfpbcDmiFhTdCxt9qaIeC3ZCMJ/k5pgZ7NdgdcCX4yI1wBPAqUaHt+JYBZKbehfBy6NiCuLjqfd0mH5DcDhRccyQwcDf5ra1EeAQyRdUmxIMxcRG9PfzcBVZCMKz2b3A/dXHIFeQZYYSsOJYJZJJ1UvAO6KiHOLjqddJC2StDA9nwccBtxdbFQzExEfjoilETFANpTK9RHxjoLDmhFJ81MnBVLzyR8Bs7pXXkQ8BNwn6RVp1qHArO580ayuHX20HSRdBgwBe0m6H/hYRFxQbFQzdjBwAjCe2tMBzoiIbxcYUzssBi5ONy7aBbg8Inqiu2WP6Qeuyn6PsCvwzxHx3WJDaotTgEtTj6F7gb8qOJ6O6unuo2ZmVp+bhszMSs6JwMys5JwIzMxKzonAzKzknAjMzErOicAMSCO6/nHVvFMlfXGadSZqvWY2mzgRmGUuI7voq9Kxab5ZT3MiMMtcARyRLiiaHNBvb+B2SddJui2NwX9k9YqShirvNSDpC5JOSs+XS7oxDdD2vTSMuFlXcSIwAyLiUeBWsoHUIDsauBx4Gjg6DbI2DJyThvmoK40J9XngmIhYDlwIfLLdsZvNVE8PMWHWpMnmoavT35MBAZ9KI2xuJ7v3Qz/wUAPbewVwALA65Y45wIPtD9tsZpwIzHa4GjhP0mvJ7lC1JjXxLAKWR8QzaSTR3avW28bOR9eTrwtYFxGluu2hzT5uGjJL0h3SbiBrwpk8SbyA7J4Cz0gaBvadYtUNwCslvSCNoHpomv9TYNHk/W8l7SbpVblWwqwFPiIw29llZGPsT/YguhT4lqRxYIwphsaOiPskXU42HPPPgdvT/N9IOgb4h3Q7xF3J7li2LvdamDXBo4+amZWcm4bMzErOicDMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzEru/wO2lWfvXT65iwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
