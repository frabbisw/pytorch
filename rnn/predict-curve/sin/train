{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nfrom tqdm import tqdm as tq\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sample():\n    start = random.randint(0,100)\n    nos = 100\n    step = .05\n    samples = torch.arange(start=start, end=start+nos*step, step=step, device=device)\n    sins = torch.sin(samples)\n    \n    X = sins[:50]\n    Y = sins[50:]\n    \n    return X.view(-1,1,1,1),Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SineEncoder(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(SineEncoder, self).__init__()\n        self.input_size=input_size\n        self.hidden_size=hidden_size\n        self.lstm = nn.LSTM(input_size=input_size,\n                    hidden_size=hidden_size,\n                    num_layers=1,\n                    batch_first=False,\n                    bidirectional=False)\n        \n    def init_hidden(self):\n        return (torch.zeros(1, 1, self.hidden_size, device=device), \n                torch.zeros(1, 1, self.hidden_size, device=device))\n        \n    def forward(self, input_tensor, hidden_tensor):\n        output_tensor, hidden_tensor = self.lstm(input_tensor, hidden_tensor)\n        return hidden_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SineDecoder(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(SineDecoder, self).__init__()\n        self.input_size=input_size\n        self.hidden_size=hidden_size\n        self.output_size=output_size\n        self.lstm = nn.LSTM(input_size=input_size,\n                    hidden_size=hidden_size,\n                    num_layers=1,\n                    batch_first=False,\n                    bidirectional=False)\n        self.linear = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, input_tensor, hidden_tensor):\n        output_tensor, hidden_tensor = self.lstm(input_tensor, hidden_tensor)\n        output_tensor = self.linear(output_tensor)\n        output_tensor = torch.tanh(output_tensor)\n        return output_tensor, hidden_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = SineEncoder(1, 128).to(device)\ndecoder = SineDecoder(1, 128, 1).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optim_encoder = torch.optim.SGD(encoder.parameters(), lr=.005)\noptim_decoder = torch.optim.SGD(decoder.parameters(), lr=.005)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def set_lr(opt, lr):\n#     for p in opt.param_groups:\n#         p['lr'] = lr\n# set_lr(optim_encoder, .001)\n# set_lr(optim_decoder, .001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(n):\n    losses = 0\n    kks = 0\n    for itr in range(1, n+1):\n        X,Y = get_sample()\n        hidden_tensor = encoder.init_hidden()\n\n        for x in X:\n            hidden_tensor = encoder.forward(x, hidden_tensor)\n\n        output_tensor = X[-1]\n        loss = 0\n        kk = 0\n        for i in range(Y.shape[0]):\n            output_tensor, hidden_tensor = decoder.forward(output_tensor, hidden_tensor)\n            loss += (output_tensor.view(-1)[0] - Y[i]) ** 2\n            kk += torch.abs(output_tensor.view(-1)[0] - Y[i]).item()\n\n        losses += loss.item()\n        kks += kk\n        \n        optim_encoder.zero_grad()\n        optim_decoder.zero_grad()\n\n        loss.backward()\n\n        optim_encoder.step()\n        optim_decoder.step()\n        \n        if itr % (n/25) == 0:\n            print(100*itr/n, losses/itr, kks/itr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(400000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.eval()\ndecoder.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test():\n    X,Y = get_sample()\n    hidden_tensor = encoder.init_hidden()\n\n    for x in X:\n        hidden_tensor = encoder.forward(x, hidden_tensor)\n    \n    kk = 0\n    Y_pred = []\n    output_tensor = X[-1]\n    for i in range(Y.shape[0]):\n        output_tensor, hidden_tensor = decoder.forward(output_tensor, hidden_tensor)\n        Y_pred.append(output_tensor.view(-1)[0].item())\n        \n    print(Y.cpu().detach().numpy())\n    print(np.array(Y_pred))\n    print(kk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = {'optim_encoder' : optim_encoder, 'optim_decoder' : optim_decoder, 'encoder_state_dict': encoder.state_dict(),  'decoder_state_dict': decoder.state_dict()}\ntorch.save(checkpoint, \"checkpoint.pth\")\n\ntext_file = open(\"hudai.txt\", \"w\")\ntext_file.write('hehe')\ntext_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
